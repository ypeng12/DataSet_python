{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-04-29T01:06:37.341845Z","iopub.status.busy":"2023-04-29T01:06:37.341584Z","iopub.status.idle":"2023-04-29T01:06:37.418932Z","shell.execute_reply":"2023-04-29T01:06:37.417766Z","shell.execute_reply.started":"2023-04-29T01:06:37.341820Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T01:06:37.421544Z","iopub.status.busy":"2023-04-29T01:06:37.420946Z","iopub.status.idle":"2023-04-29T01:06:37.466883Z","shell.execute_reply":"2023-04-29T01:06:37.465754Z","shell.execute_reply.started":"2023-04-29T01:06:37.421506Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","3            4         1       1   \n","4            5         0       3   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","0                            Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                             Heikkinen, Miss. Laina  female  26.0      0   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                           Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch            Ticket     Fare Cabin Embarked  \n","0      0         A/5 21171   7.2500   NaN        S  \n","1      0          PC 17599  71.2833   C85        C  \n","2      0  STON/O2. 3101282   7.9250   NaN        S  \n","3      0            113803  53.1000  C123        S  \n","4      0            373450   8.0500   NaN        S  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["train_data = pd.read_csv(\"train.csv\")\n","train_data.head()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T01:06:37.468907Z","iopub.status.busy":"2023-04-29T01:06:37.468416Z","iopub.status.idle":"2023-04-29T01:06:37.495451Z","shell.execute_reply":"2023-04-29T01:06:37.494356Z","shell.execute_reply.started":"2023-04-29T01:06:37.468867Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>892</td>\n","      <td>3</td>\n","      <td>Kelly, Mr. James</td>\n","      <td>male</td>\n","      <td>34.5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>330911</td>\n","      <td>7.8292</td>\n","      <td>NaN</td>\n","      <td>Q</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>893</td>\n","      <td>3</td>\n","      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n","      <td>female</td>\n","      <td>47.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>363272</td>\n","      <td>7.0000</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>894</td>\n","      <td>2</td>\n","      <td>Myles, Mr. Thomas Francis</td>\n","      <td>male</td>\n","      <td>62.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>240276</td>\n","      <td>9.6875</td>\n","      <td>NaN</td>\n","      <td>Q</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>895</td>\n","      <td>3</td>\n","      <td>Wirz, Mr. Albert</td>\n","      <td>male</td>\n","      <td>27.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>315154</td>\n","      <td>8.6625</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>896</td>\n","      <td>3</td>\n","      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n","      <td>female</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3101298</td>\n","      <td>12.2875</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Pclass                                          Name     Sex  \\\n","0          892       3                              Kelly, Mr. James    male   \n","1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n","2          894       2                     Myles, Mr. Thomas Francis    male   \n","3          895       3                              Wirz, Mr. Albert    male   \n","4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n","\n","    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n","0  34.5      0      0   330911   7.8292   NaN        Q  \n","1  47.0      1      0   363272   7.0000   NaN        S  \n","2  62.0      0      0   240276   9.6875   NaN        Q  \n","3  27.0      0      0   315154   8.6625   NaN        S  \n","4  22.0      1      1  3101298  12.2875   NaN        S  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["test_data = pd.read_csv(\"test.csv\")\n","test_data.head()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T01:06:37.499399Z","iopub.status.busy":"2023-04-29T01:06:37.499096Z","iopub.status.idle":"2023-04-29T01:06:37.513525Z","shell.execute_reply":"2023-04-29T01:06:37.512240Z","shell.execute_reply.started":"2023-04-29T01:06:37.499370Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["% of women who survived: 0.7420382165605095\n"]}],"source":["women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\n","rate_women = sum(women)/len(women)\n","\n","print(\"% of women who survived:\", rate_women)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T01:06:37.516174Z","iopub.status.busy":"2023-04-29T01:06:37.515131Z","iopub.status.idle":"2023-04-29T01:06:37.523482Z","shell.execute_reply":"2023-04-29T01:06:37.522208Z","shell.execute_reply.started":"2023-04-29T01:06:37.516138Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["% of men who survived: 0.18890814558058924\n"]}],"source":["men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\n","rate_men = sum(men)/len(men)\n","\n","print(\"% of men who survived:\", rate_men)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T01:06:37.525904Z","iopub.status.busy":"2023-04-29T01:06:37.525224Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-04-28 21:09:06.475893: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","28/28 [==============================] - 1s 2ms/step - loss: 0.6285 - accuracy: 0.7217\n","Epoch 2/50\n","28/28 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.8092\n","Epoch 3/50\n","28/28 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.8114\n","Epoch 4/50\n","28/28 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8182\n","Epoch 5/50\n","28/28 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.8227\n","Epoch 6/50\n","28/28 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8204\n","Epoch 7/50\n","28/28 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8350\n","Epoch 8/50\n","28/28 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8373\n","Epoch 9/50\n","28/28 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8406\n","Epoch 10/50\n","28/28 [==============================] - 0s 1ms/step - loss: 0.3951 - accuracy: 0.8429\n","Epoch 11/50\n","28/28 [==============================] - 0s 1ms/step - loss: 0.3938 - accuracy: 0.8429\n","Epoch 12/50\n","28/28 [==============================] - 0s 1ms/step - loss: 0.3899 - accuracy: 0.8429\n","Epoch 13/50\n","28/28 [==============================] - 0s 1ms/step - loss: 0.3906 - accuracy: 0.8451\n","Epoch 14/50\n","28/28 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8451\n","Epoch 15/50\n","28/28 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8418\n","Epoch 16/50\n","28/28 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8451\n","Epoch 17/50\n","28/28 [==============================] - 0s 1ms/step - loss: 0.3832 - accuracy: 0.8474\n","Epoch 18/50\n","28/28 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8474\n","Epoch 19/50\n","28/28 [==============================] - 0s 3ms/step - loss: 0.3787 - accuracy: 0.8474\n","Epoch 20/50\n","28/28 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8462\n","Epoch 21/50\n","28/28 [==============================] - 0s 3ms/step - loss: 0.3754 - accuracy: 0.8507\n","Epoch 22/50\n","28/28 [==============================] - 0s 3ms/step - loss: 0.3758 - accuracy: 0.8474\n","Epoch 23/50\n","28/28 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8462\n","Epoch 24/50\n","28/28 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8485\n","Epoch 25/50\n","28/28 [==============================] - 0s 3ms/step - loss: 0.3705 - accuracy: 0.8507\n","Epoch 26/50\n","28/28 [==============================] - 0s 3ms/step - loss: 0.3696 - accuracy: 0.8496\n","Epoch 27/50\n","28/28 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8485\n","Epoch 28/50\n","28/28 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8462\n","Epoch 29/50\n","28/28 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8474\n","Epoch 30/50\n","28/28 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8440\n","Epoch 31/50\n","28/28 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8496\n","Epoch 32/50\n","28/28 [==============================] - 0s 6ms/step - loss: 0.3622 - accuracy: 0.8496\n","Epoch 33/50\n","28/28 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8451\n","Epoch 34/50\n","28/28 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8462\n","Epoch 35/50\n","28/28 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8485\n","Epoch 36/50\n","28/28 [==============================] - 0s 4ms/step - loss: 0.3598 - accuracy: 0.8440\n","Epoch 37/50\n","28/28 [==============================] - 0s 1ms/step - loss: 0.3606 - accuracy: 0.8496\n","Epoch 38/50\n","28/28 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8485\n","Epoch 39/50\n","28/28 [==============================] - 0s 1ms/step - loss: 0.3593 - accuracy: 0.8462\n","Epoch 40/50\n","28/28 [==============================] - 0s 1ms/step - loss: 0.3571 - accuracy: 0.8485\n","Epoch 41/50\n","28/28 [==============================] - 0s 1ms/step - loss: 0.3560 - accuracy: 0.8474\n","Epoch 42/50\n","28/28 [==============================] - 0s 1ms/step - loss: 0.3555 - accuracy: 0.8474\n","Epoch 43/50\n","28/28 [==============================] - 0s 1ms/step - loss: 0.3520 - accuracy: 0.8496\n","Epoch 44/50\n","28/28 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.8530\n","Epoch 45/50\n","28/28 [==============================] - 0s 1ms/step - loss: 0.3533 - accuracy: 0.8530\n","Epoch 46/50\n","28/28 [==============================] - 0s 1ms/step - loss: 0.3509 - accuracy: 0.8429\n","Epoch 47/50\n","28/28 [==============================] - 0s 1ms/step - loss: 0.3494 - accuracy: 0.8496\n","Epoch 48/50\n","28/28 [==============================] - 0s 1ms/step - loss: 0.3491 - accuracy: 0.8541\n","Epoch 49/50\n","28/28 [==============================] - 0s 1ms/step - loss: 0.3488 - accuracy: 0.8507\n","Epoch 50/50\n","28/28 [==============================] - 0s 1ms/step - loss: 0.3488 - accuracy: 0.8496\n","14/14 [==============================] - 0s 820us/step\n","Submission file created successfully!\n"]}],"source":["import tensorflow as tf\n","from sklearn.preprocessing import StandardScaler\n","\n","# Preprocessing\n","train_data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n","test_data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n","\n","# Handle missing values in 'Age' and 'Embarked' columns\n","train_data['Age'].fillna(train_data['Age'].median(), inplace=True)\n","train_data['Embarked'].fillna(train_data['Embarked'].mode()[0], inplace=True)\n","test_data['Age'].fillna(test_data['Age'].median(), inplace=True)\n","test_data['Fare'].fillna(test_data['Fare'].median(), inplace=True)\n","\n","# Convert 'Sex' and 'Embarked' columns to numerical values\n","train_data.replace({'Sex': {'male': 0, 'female': 1}, 'Embarked': {'S': 0, 'C': 1, 'Q': 2}}, inplace=True)\n","test_data.replace({'Sex': {'male': 0, 'female': 1}, 'Embarked': {'S': 0, 'C': 1, 'Q': 2}}, inplace=True)\n","\n","# Standardize the numerical features\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(train_data.drop('Survived', axis=1))\n","y_train = train_data['Survived'].values.reshape(-1, 1)\n","X_test = scaler.transform(test_data)\n","\n","# Define the model architecture\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Dense(units=64, activation='relu', input_shape=[X_train.shape[1]]),\n","    tf.keras.layers.Dense(units=64, activation='relu'),\n","    tf.keras.layers.Dense(units=1, activation='sigmoid')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(X_train, y_train, epochs=50, batch_size=32)\n","\n","# Make predictions on the test set\n","predictions = model.predict(X_test)\n","predictions = np.round(predictions).astype(int).flatten()\n","\n","# Create the submission file\n","submission = pd.DataFrame({'PassengerId': test_data.index + 892, 'Survived': predictions})\n","submission.to_csv('submission.csv', index=False)\n","\n","print(\"Submission file created successfully!\")"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/titanic/gender_submission.csv'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/var/folders/2y/8s7bchdx6kq7jlr6rhgvhnv00000gn/T/ipykernel_79035/318840378.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load actual survival values from gender_submission.csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mactual_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/titanic/gender_submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my_actual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactual_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Survived'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/titanic/gender_submission.csv'"]}],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# Load actual survival values from gender_submission.csv\n","actual_data = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')\n","y_actual = actual_data['Survived'].values\n","\n","# Load predicted survival values from submission.csv\n","predicted_data = pd.read_csv('/kaggle/working/submission.csv')\n","y_predicted = predicted_data['Survived'].values\n","\n","# Calculate evaluation metrics\n","accuracy = accuracy_score(y_actual, y_predicted)\n","precision = precision_score(y_actual, y_predicted)\n","recall = recall_score(y_actual, y_predicted)\n","f1 = f1_score(y_actual, y_predicted)\n","\n","# Print evaluation metrics\n","print(f'Accuracy: {accuracy}')\n","print(f'Precision: {precision}')\n","print(f'Recall: {recall}')\n","print(f'F1-Score: {f1}')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":4}
